{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import warnings\n",
    "import matplotlib.pyplot as plt\n",
    "import soundfile as sf\n",
    "from scipy.fft import rfft, rfftfreq\n",
    "import librosa\n",
    "import librosa.display\n",
    "import IPython.display as ipd\n",
    "import os\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report\n",
    "import pickle\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.mixture import GaussianMixture\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "warnings.filterwarnings('ignore')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mfcc_feature_extractor(audio, sampleRate):\n",
    "    mfccsFeatures = librosa.feature.mfcc(y=audio, sr=sampleRate, n_mfcc=40)\n",
    "    mfccsScaledFeatures = np.mean(mfccsFeatures.T, axis=0)\n",
    "\n",
    "    return mfccsScaledFeatures\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "def contrast_feature_extractor(audio, sampleRate):\n",
    "    stft = np.abs(librosa.stft(audio))\n",
    "    contrast = librosa.feature.spectral_contrast(S=stft, sr=sampleRate)\n",
    "    contrastScaled = np.mean(contrast.T, axis=0)\n",
    "\n",
    "    return contrastScaled\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tonnetz_feature_extractor(audio, sampleRate):\n",
    "    tonnetz = librosa.feature.tonnetz(\n",
    "        y=librosa.effects.harmonic(audio), sr=sampleRate)\n",
    "    tonnetzScaled = np.mean(tonnetz.T, axis=0)\n",
    "\n",
    "    return tonnetzScaled\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "def chroma_feature_extractor(audio,sampleRate):\n",
    "    stft = np.abs(librosa.stft(audio))\n",
    "    chroma = librosa.feature.chroma_stft(S=stft,sr=sampleRate)\n",
    "    chromaScaled = np.mean(chroma.T,axis=0)\n",
    "    \n",
    "    return chromaScaled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "def features_extractor(file):\n",
    "    features=[]\n",
    "    audio, sampleRate = librosa.load(file, res_type='kaiser_fast') \n",
    "    mfcc=mfcc_feature_extractor(audio,sampleRate)\n",
    "    contrast = contrast_feature_extractor(audio,sampleRate)\n",
    "    tonnetz = tonnetz_feature_extractor(audio,sampleRate)\n",
    "    chroma = chroma_feature_extractor(audio,sampleRate)\n",
    "\n",
    "    features.append([mfcc,contrast,tonnetz,chroma])\n",
    "    features[0] = np.concatenate((features[0][0],features[0][1],features[0][2],features[0][3]))\n",
    "    return features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_features(extractedFeatures,dirPath,label):\n",
    "    for file in os.listdir(dirPath):\n",
    "        filePath = dirPath+'/'+file\n",
    "        finalClassLabels=label\n",
    "        audio, sampleRate = librosa.load(filePath, res_type='kaiser_fast') \n",
    "        mfcc=mfcc_feature_extractor(audio,sampleRate)\n",
    "        contrast = contrast_feature_extractor(audio,sampleRate)\n",
    "        tonnetz = tonnetz_feature_extractor(audio,sampleRate)\n",
    "        chroma = chroma_feature_extractor(audio,sampleRate)\n",
    "        extractedFeatures.append([mfcc,contrast,tonnetz,chroma,finalClassLabels])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "dict = {\"open the door\":[\"C:/Users/EXTRA/DSP_Task3/processing/anwar\",\n",
    "\"C:/Users/EXTRA/DSP_Task3/processing/aya\",\n",
    "\"C:/Users/EXTRA/DSP_Task3/processing/ehab\",\n",
    "\"C:/Users/EXTRA/DSP_Task3/processing/zeyad\"],\n",
    "\"others\":[\"C:/Users/EXTRA/DSP_Task3/processing/words/Anwar\",\n",
    "\"C:/Users/EXTRA/DSP_Task3/processing/words/Aya\",\n",
    "\"C:/Users/EXTRA/DSP_Task3/processing/words/Ehab\",\n",
    "\"C:/Users/EXTRA/DSP_Task3/processing/words/Zeyad\"]}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "extractedFeatures = []\n",
    "for i in dict.keys():\n",
    "    for x in dict[i]:\n",
    "        add_features(extractedFeatures,x,i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(807, 5)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>count</th>\n",
       "      <th>unique</th>\n",
       "      <th>top</th>\n",
       "      <th>freq</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>mfcc</th>\n",
       "      <td>807</td>\n",
       "      <td>807</td>\n",
       "      <td>[-358.41626, 144.1046, -4.3864827, 17.072119, ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>contrast</th>\n",
       "      <td>807</td>\n",
       "      <td>807</td>\n",
       "      <td>[18.94650314889134, 16.090433605334066, 20.062...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>tonnetz</th>\n",
       "      <td>807</td>\n",
       "      <td>807</td>\n",
       "      <td>[0.00294895926736136, 0.022882545163613432, 0....</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>chroma</th>\n",
       "      <td>807</td>\n",
       "      <td>807</td>\n",
       "      <td>[0.4624628, 0.5353802, 0.56193304, 0.61254495,...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>class</th>\n",
       "      <td>807</td>\n",
       "      <td>2</td>\n",
       "      <td>others</td>\n",
       "      <td>411</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         count unique                                                top freq\n",
       "mfcc       807    807  [-358.41626, 144.1046, -4.3864827, 17.072119, ...    1\n",
       "contrast   807    807  [18.94650314889134, 16.090433605334066, 20.062...    1\n",
       "tonnetz    807    807  [0.00294895926736136, 0.022882545163613432, 0....    1\n",
       "chroma     807    807  [0.4624628, 0.5353802, 0.56193304, 0.61254495,...    1\n",
       "class      807      2                                             others  411"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data=pd.DataFrame(extractedFeatures,columns=['mfcc','contrast','tonnetz','chroma','class'])\n",
    "print(data.shape)\n",
    "data.describe().T\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mfcc</th>\n",
       "      <th>contrast</th>\n",
       "      <th>tonnetz</th>\n",
       "      <th>chroma</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>802</th>\n",
       "      <td>[-403.88452, 100.31129, 12.981465, 7.540295, 4...</td>\n",
       "      <td>[18.54460786172384, 15.118820966669379, 20.905...</td>\n",
       "      <td>[0.03725058376652236, 0.020743784015899776, 0....</td>\n",
       "      <td>[0.53858376, 0.5033339, 0.4697587, 0.41963324,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>803</th>\n",
       "      <td>[-394.7898, 95.47343, 18.773857, 13.397423, 1....</td>\n",
       "      <td>[18.5922662615676, 15.69210975263843, 20.65567...</td>\n",
       "      <td>[0.04421657448567877, 0.056314648814841974, 0....</td>\n",
       "      <td>[0.64130944, 0.54192483, 0.44760096, 0.4129084...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>804</th>\n",
       "      <td>[-395.23132, 95.21313, 24.915659, 11.414965, 6...</td>\n",
       "      <td>[19.597071542742974, 15.07755072043609, 18.950...</td>\n",
       "      <td>[0.08172407391847117, 0.011595188249279607, 0....</td>\n",
       "      <td>[0.6179552, 0.530558, 0.5153319, 0.4904323, 0....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>805</th>\n",
       "      <td>[-407.15182, 80.67283, 25.647009, 16.32321, 7....</td>\n",
       "      <td>[19.328894678503787, 15.005299721334753, 18.62...</td>\n",
       "      <td>[0.03602475840749593, 0.0644023130509403, -0.0...</td>\n",
       "      <td>[0.6979088, 0.66097105, 0.58876884, 0.5688891,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>806</th>\n",
       "      <td>[-425.70676, 78.90517, 27.258017, 16.093987, 1...</td>\n",
       "      <td>[18.075636513475803, 14.369919534135114, 17.71...</td>\n",
       "      <td>[0.06542340934393284, 0.05735679501281795, 0.0...</td>\n",
       "      <td>[0.6332846, 0.6711462, 0.6781552, 0.6142667, 0...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  mfcc  \\\n",
       "802  [-403.88452, 100.31129, 12.981465, 7.540295, 4...   \n",
       "803  [-394.7898, 95.47343, 18.773857, 13.397423, 1....   \n",
       "804  [-395.23132, 95.21313, 24.915659, 11.414965, 6...   \n",
       "805  [-407.15182, 80.67283, 25.647009, 16.32321, 7....   \n",
       "806  [-425.70676, 78.90517, 27.258017, 16.093987, 1...   \n",
       "\n",
       "                                              contrast  \\\n",
       "802  [18.54460786172384, 15.118820966669379, 20.905...   \n",
       "803  [18.5922662615676, 15.69210975263843, 20.65567...   \n",
       "804  [19.597071542742974, 15.07755072043609, 18.950...   \n",
       "805  [19.328894678503787, 15.005299721334753, 18.62...   \n",
       "806  [18.075636513475803, 14.369919534135114, 17.71...   \n",
       "\n",
       "                                               tonnetz  \\\n",
       "802  [0.03725058376652236, 0.020743784015899776, 0....   \n",
       "803  [0.04421657448567877, 0.056314648814841974, 0....   \n",
       "804  [0.08172407391847117, 0.011595188249279607, 0....   \n",
       "805  [0.03602475840749593, 0.0644023130509403, -0.0...   \n",
       "806  [0.06542340934393284, 0.05735679501281795, 0.0...   \n",
       "\n",
       "                                                chroma  \n",
       "802  [0.53858376, 0.5033339, 0.4697587, 0.41963324,...  \n",
       "803  [0.64130944, 0.54192483, 0.44760096, 0.4129084...  \n",
       "804  [0.6179552, 0.530558, 0.5153319, 0.4904323, 0....  \n",
       "805  [0.6979088, 0.66097105, 0.58876884, 0.5688891,...  \n",
       "806  [0.6332846, 0.6711462, 0.6781552, 0.6142667, 0...  "
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features = data.iloc[:, 0:-1]\n",
    "target = data['class']\n",
    "features.tail()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = features.values.tolist()\n",
    "for i in range(len(features)):\n",
    "    features[i] = np.concatenate((features[i][0],features[i][1],features[i][2],features[i][3]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder = LabelEncoder()\n",
    "target = encoder.fit_transform(target)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "xTrain, xTest, yTrain, yTest = train_test_split(features, target, test_size=0.25, random_state=105)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-5 {color: black;background-color: white;}#sk-container-id-5 pre{padding: 0;}#sk-container-id-5 div.sk-toggleable {background-color: white;}#sk-container-id-5 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-5 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-5 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-5 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-5 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-5 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-5 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-5 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-5 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-5 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-5 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-5 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-5 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-5 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-5 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-5 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-5 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-5 div.sk-item {position: relative;z-index: 1;}#sk-container-id-5 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-5 div.sk-item::before, #sk-container-id-5 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-5 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-5 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-5 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-5 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-5 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-5 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-5 div.sk-label-container {text-align: center;}#sk-container-id-5 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-5 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-5\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>SVC(decision_function_shape=&#x27;ovo&#x27;, kernel=&#x27;linear&#x27;)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-5\" type=\"checkbox\" checked><label for=\"sk-estimator-id-5\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">SVC</label><div class=\"sk-toggleable__content\"><pre>SVC(decision_function_shape=&#x27;ovo&#x27;, kernel=&#x27;linear&#x27;)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "SVC(decision_function_shape='ovo', kernel='linear')"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classifier = SVC(kernel='linear', decision_function_shape=\"ovo\")\n",
    "classifier.fit(xTrain,yTrain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds = classifier.predict(xTest)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prediction(pred):\n",
    "    if pred == 0:\n",
    "        print(\"Correct!\")\n",
    "    elif pred == 1:\n",
    "        print(\"Wrong password\")\n",
    "  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.99      0.99       100\n",
      "           1       0.99      0.99      0.99       102\n",
      "\n",
      "    accuracy                           0.99       202\n",
      "   macro avg       0.99      0.99      0.99       202\n",
      "weighted avg       0.99      0.99      0.99       202\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(yTest,preds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Correct!\n",
      "Wrong password\n"
     ]
    }
   ],
   "source": [
    "testFeatures = features_extractor(\n",
    "    \"C:/Users/EXTRA/DSP_Task3/processing/ehab/voice1619028.wav\")\n",
    "pred = classifier.predict(testFeatures)\n",
    "prediction(pred)\n",
    "testFeatures = features_extractor(\n",
    "    \"C:/Users/EXTRA/DSP_Task3/processing/words/Anwar/voice28110762.wav\")\n",
    "pred = classifier.predict(testFeatures)\n",
    "prediction(pred)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "pickle_out = open(\"password_model.pkl\", \"wb\")\n",
    "pickle.dump(classifier, pickle_out)\n",
    "pickle_out.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "b35c0e0c22f4e69d6176338ddf1640bc0c3891cabe89a14316f917f290cba1ea"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
